# -*- coding: utf-8 -*-
"""Streamlit_ChatBot_MIE1624_Part_5_ItDS_Group_10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12EK0mrCdQeQZ3XZgkVoToWHHl-b1J8Mi
"""

# 1.1 Set OpenAI API Key
import os
import streamlit as st

os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
print("Key loaded:", os.getenv("OPENAI_API_KEY") is not None)

# Quick sanity check
print("API key set?", os.getenv("OPENAI_API_KEY") is not None)

# 2. LOAD AND STRUCTURE PROJECT DOCUMENTS (RAG INPUT)

from pathlib import Path
import pandas as pd
import json
from langchain_core.documents import Document as LCDocument

from pathlib import Path
BASE_DIR = Path(".")

docs_raw = []

# ---------- 2.1 MAIN REPORT (txt) ----------
from pathlib import Path
from langchain_core.documents import Document as LCDocument

BASE_DIR = Path(".")

# 1) MAIN REPORT â€“ now loaded from plain text file
report_txt_path = BASE_DIR / "group10_report.txt"
if not report_txt_path.exists():
    raise FileNotFoundError(f"Missing report text file: {report_txt_path}")

report_text = report_txt_path.read_text(encoding="utf-8")

docs_raw = []
docs_raw.append(
    LCDocument(
        page_content=report_text,
        metadata={"source": "group10_report"}
    )
)

# ---------- 2.2 CIFAR PILLAR SUMMARY (CSV) ----------
cifar_path = BASE_DIR / "cifar_pillar_summary.csv"
assert cifar_path.exists(), f"CIFAR CSV not found at {cifar_path}"
df_cifar = pd.read_csv(cifar_path)

required_cifar_cols = [
    "pillar",
    "pillar_summary",
    "key_competitiveness_factors",
    "proposed_strategies",
    "current_strengths",
    "current_weaknesses",
]
missing = [c for c in required_cifar_cols if c not in df_cifar.columns]
if missing:
    raise ValueError(f"Missing columns in cifar_pillar_summary.csv: {missing}")

for _, row in df_cifar.iterrows():
    pillar = row["pillar"]
    text = f"""CIFAR pillar analysis â€“ {pillar}

Summary:
{row['pillar_summary']}

Key competitiveness factors:
{row['key_competitiveness_factors']}

Proposed strategies:
{row['proposed_strategies']}

Current strengths:
{row['current_strengths']}

Current weaknesses:
{row['current_weaknesses']}
"""
    docs_raw.append(
        LCDocument(
            page_content=text,
            metadata={
                "source": "cifar_pillars",
                "pillar": pillar
            }
        )
    )

# ---------- 2.3 COUNTRY COMPETITIVENESS & INVESTMENTS (CSV) ----------
comp_path = BASE_DIR / "country_competitiveness_indicators_investments.csv"
assert comp_path.exists(), f"Competitiveness CSV not found at {comp_path}"
df_comp = pd.read_csv(comp_path)

required_comp_cols = [
    "country",
    "key_indicators",
    "priority_investment_areas",
    "self_assessed_position",
    "self_assessed_score",
    "short_summary",
]
missing = [c for c in required_comp_cols if c not in df_comp.columns]
if missing:
    raise ValueError(f"Missing columns in country_competitiveness_indicators_investments.csv: {missing}")

for _, row in df_comp.iterrows():
    country = row["country"]
    text = f"""Country competitiveness & investments â€“ {country}:

Key indicators:
{row['key_indicators']}

Priority investment areas:
{row['priority_investment_areas']}

Self-assessed position:
{row['self_assessed_position']}

Self-assessed score: {row['self_assessed_score']}

Short summary:
{row['short_summary']}
"""
    docs_raw.append(
        LCDocument(
            page_content=text,
            metadata={
                "source": "country_competitiveness",
                "country": country
            }
        )
    )

# ---------- 2.4 COUNTRY STRATEGY SUMMARIES (JSON) ----------
strategy_path = BASE_DIR / "country_strategy_summaries.json"
assert strategy_path.exists(), f"Strategy JSON not found at {strategy_path}"
with open(strategy_path, "r", encoding="utf-8") as f:
    strategy_data = json.load(f)

if isinstance(strategy_data, dict):
    # If it's a dict keyed by country, convert to list
    entries = strategy_data.values()
else:
    entries = strategy_data

for entry in entries:
    country = entry.get("country", "unknown")
    summary = entry.get("strategy_summary", "")
    objectives = entry.get("core_objectives", [])
    top_pillar = entry.get("top_priority_pillar", "")
    takeaways = entry.get("top_5_takeaways", [])

    text = f"""AI strategy summary â€“ {country}:

Overall strategy:
{summary}

Core objectives:
{objectives}

Top priority pillar:
{top_pillar}

Top 5 takeaways:
{takeaways}
"""
    docs_raw.append(
        LCDocument(
            page_content=text,
            metadata={
                "source": "country_strategy_summary",
                "country": country
            }
        )
    )

print(f"Total base documents before chunking: {len(docs_raw)}")

# ============================================================
# 3. BUILD RAG INDEX (CHUNKING + EMBEDDINGS + CHROMA)
# ============================================================
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# Split the loaded documents into chunks
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1200,
    chunk_overlap=200,
    separators=["\n\n", "\n", ". ", " "]
)

docs = splitter.split_documents(docs_raw)
print(f"Total chunks after splitting: {len(docs)}")

# Embeddings (you can switch to "text-embedding-3-large" if you want max quality)
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# Build the Chroma vector store
vectorstore = Chroma.from_documents(
    docs,
    embedding=embeddings,
    collection_name="group10_canada_ai_strategy"
)

# Create a retriever interface (LangChain Runnable retriever)
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})


# ============================================================
# 4. DEFINE RAG TOOL FOR CREWAI
# ============================================================
from crewai.tools import tool

@tool("project_rag_search")
def project_rag_search(query: str) -> str:
    """
    Search Group 10's project findings:
    - Main consulting report (our strategy and conclusions)
    - CIFAR pillar summary (our sentiment analysis)
    - Country competitiveness & investment indicators
    - Country strategy summaries

    Use this to answer questions about our analysis and recommendations
    for Canada's AI strategy, and how it compares to other countries.
    """
    # New LangChain retrievers use .invoke(...) instead of get_relevant_documents(...)
    results = retriever.invoke(query)
    snippets = []
    for r in results:
        src = r.metadata.get("source", "unknown")
        snippets.append(f"[{src}]\n{r.page_content}")
    # Trim in case of long context
    return "\n\n".join(snippets)[:6000]


# Quick test of the tool (OPTION 1: use .run for Tool objects)
print("\nSample RAG search for 'Canada infrastructure weaknesses':\n")
print(project_rag_search.run("Canada infrastructure weaknesses")[:1000])

# 5. DEFINE CREWAI AGENT (SINGLE CHATBOT AGENT)
from crewai import Agent
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-4.1-mini",   # You can change to another model if needed
    temperature=0.2
)

chatbot_agent = Agent(
    role="Canada AI Strategy Chatbot",
    goal=(
        "Answer any user question about Group 10's findings on Canada's AI strategy, "
        "based on our MIE1624 project (Parts 1â€“4)."
    ),
    backstory=(
        "You are the official chatbot for Group 10â€™s MIE1624 project. "
        "You know our modeling results, CIFAR pillar analysis, cross-country comparisons, "
        "and our three-stage Canadian AI strategy with implementation details. "
        "You always use the project_rag_search tool to ground your answers in the project documents. "
        "When there is a conflict, prioritize the interpretation and recommendations in the Group 10 report."
    ),
    tools=[project_rag_search],
    llm=llm,
    max_iter=1
)

# 6. DEFINE TASK / CREW RUNNER (ONE-TURN CHAT)
from crewai import Task, Crew, Process

def build_task(user_question: str) -> Task:
    return Task(
        description=(
            "A user has asked the following question about our project on Canada's AI strategy:\n\n"
            f"'{user_question}'\n\n"
            "1. Use the project_rag_search tool to retrieve relevant context from the project.\n"
            "2. Based only on that context, answer clearly and concisely.\n"
            "3. Where helpful, mention whether the answer comes from our data analysis, "
            "our strategy proposal, our implementation steps, or our global comparison."
        ),
        agent=chatbot_agent,
        tools=[project_rag_search],
        expected_output=(
            "A well-structured, evidence-based answer grounded in our project documents."
        ),
        markdown=True
    )

def ask_project_chatbot(question: str) -> str:
    """Run one question through the CrewAI chatbot and return the answer."""
    task = build_task(question)
    crew = Crew(
        agents=[chatbot_agent],
        tasks=[task],
        process=Process.sequential,
        verbose=False
    )
    result = crew.kickoff()
    return result

# ====== the Streamlit interface starts here ======
import streamlit as st

st.set_page_config(
    page_title="MIE1624 â€“ Canada AI Strategy Chatbot (Group 10)",
    page_icon="ðŸ¤–",
    layout="wide",
)

st.title("ðŸ¤– MIE1624 â€“ Canadaâ€™s AI Strategy Chatbot (Group 10)")
st.markdown(
    """
This chatbot uses our Group 10 MIE1624 project (report, CIFAR analysis,
competitiveness indicators, and country strategy summaries) as its knowledge base.
Ask anything about Canada's AI strategy and our findings.
"""
)

# Retrieve API Key from Streamlit Secrets
import os
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
else:
    st.error("No OPENAI_API_KEY found in Streamlit secrets.")
    st.stop()

# Optional: cache expensive initialization (docs_raw, retriever, Agent, etc.)
@st.cache_resource(show_spinner="Loading chatbot and project documentsâ€¦")
def init_chatbot():
    # THIS is where your existing initialization code goes:
    # - create docs_raw
    # - build RAG index / retriever
    # - define project_rag_search tool
    # - chatbot_agent, build_task, ask_project_chatbot(...)
    #
    # In the end ONLY return the function that answers a question:
    return ask_project_chatbot

ask_project_chatbot_fn = init_chatbot()

# Store chat history in Session-State
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display previous messages
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Input field
user_q = st.chat_input("Ask about Canadaâ€™s AI strategy and our project findingsâ€¦")
if user_q:
    # Show and save user message
    st.session_state.messages.append({"role": "user", "content": user_q})
    with st.chat_message("user"):
        st.markdown(user_q)

    # Get answer from the existing CrewAI chatbot
    with st.chat_message("assistant"):
        with st.spinner("Thinking with our project documentsâ€¦"):
            try:
                answer = ask_project_chatbot_fn(user_q)
            except Exception as e:
                answer = f"Error while answering: {e}"
            st.markdown(answer)

    st.session_state.messages.append({"role": "assistant", "content": answer})