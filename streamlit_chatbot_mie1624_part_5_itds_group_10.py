# -*- coding: utf-8 -*-
"""Streamlit_ChatBot_MIE1624_Part_5_ItDS_Group_10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HqVTLvvenSQhslsV3IHSMxKFObGfQPuA
"""

# ============================================================
# STREAMLIT CHATBOT â€“ GROUP 10 (FULLY FIXED VERSION)
# ============================================================

import os
import streamlit as st
import pandas as pd
import json
from pathlib import Path

# -----------------------------
# Load API key from secrets
# -----------------------------
if "OPENAI_API_KEY" not in st.secrets:
    st.error("Missing OPENAI_API_KEY in Streamlit secrets!")
    st.stop()
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# -----------------------------
# Streamlit page config
# -----------------------------
st.set_page_config(
    page_title="MIE1624 â€“ Canada AI Strategy Chatbot (Group 10)",
    page_icon="ðŸ¤–",
    layout="wide",
)

st.title("ðŸ¤– MIE1624 â€“ Canadaâ€™s AI Strategy Chatbot (Group 10)")
st.markdown("""
This chatbot uses our Group 10 MIE1624 project (report, CIFAR analysis,
competitiveness indicators, and country strategy summaries) as its knowledge base.
Ask anything about Canada's AI strategy and our findings.
""")

# ============================================================
#  CACHED INITIALIZATION (ALL EXPENSIVE WORK)
# ============================================================
@st.cache_resource(show_spinner="Loading documents & building RAG systemâ€¦")
def init_chatbot():
    from langchain_core.documents import Document as LCDocument
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_openai import OpenAIEmbeddings, ChatOpenAI
    from langchain_community.vectorstores import Chroma
    from crewai.tools import tool
    from crewai import Agent, Task, Crew, Process

    BASE_DIR = Path(".")

    # -------------------------
    # LOAD DOCUMENTS
    # -------------------------
    docs_raw = []

    # 1) MAIN REPORT TEXT
    report_txt_path = BASE_DIR / "group10_report.txt"
    if not report_txt_path.exists():
        raise FileNotFoundError("group10_report.txt missing in repo.")
    report_text = report_txt_path.read_text(encoding="utf-8")
    docs_raw.append(LCDocument(page_content=report_text, metadata={"source": "group10_report"}))

    # 2) CIFAR CSV
    df_cifar = pd.read_csv(BASE_DIR / "cifar_pillar_summary.csv")
    for _, row in df_cifar.iterrows():
        text = f"""
CIFAR pillar analysis â€“ {row['pillar']}

Summary:
{row['pillar_summary']}

Key competitiveness factors:
{row['key_competitiveness_factors']}

Proposed strategies:
{row['proposed_strategies']}

Strengths:
{row['current_strengths']}

Weaknesses:
{row['current_weaknesses']}
"""
        docs_raw.append(LCDocument(page_content=text, metadata={"source": "cifar"}))

    # 3) COMPETITIVENESS CSV
    df_comp = pd.read_csv(BASE_DIR / "country_competitiveness_indicators_investments.csv")
    for _, row in df_comp.iterrows():
        text = f"""
Country competitiveness â€“ {row['country']}:

Indicators: {row['key_indicators']}
Priority Areas: {row['priority_investment_areas']}
Position: {row['self_assessed_position']}
Score: {row['self_assessed_score']}
Summary: {row['short_summary']}
"""
        docs_raw.append(LCDocument(page_content=text, metadata={"source": "competitiveness"}))

    # 4) JSON
    strategy_data = json.loads((BASE_DIR / "country_strategy_summaries.json").read_text())
    for entry in strategy_data:
        text = f"""
AI Strategy Summary â€“ {entry["country"]}

Strategy:
{entry["strategy_summary"]}

Objectives:
{entry["core_objectives"]}

Top Priority:
{entry["top_priority_pillar"]}

Takeaways:
{entry["top_5_takeaways"]}
"""
        docs_raw.append(LCDocument(page_content=text, metadata={"source": "strategy_json"}))

    # -------------------------
    # BUILD RAG CHROMA INDEX
    # -------------------------
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1200,
        chunk_overlap=200
    )
    docs = splitter.split_documents(docs_raw)

    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = Chroma.from_documents(
        docs,
        embedding=embeddings,
        collection_name="group10_canada_ai_strategy"
    )
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

    # -------------------------
    # DEFINE RAG TOOL
    # -------------------------
    @tool("project_rag_search")
    def project_rag_search(query: str) -> str:
        """
        Search Group 10's project corpus (final report, CIFAR pillar analysis,
        country competitiveness indicators, and country strategy summaries)
        and return the most relevant chunks as grounding context for answers
        about Canada's AI strategy.
        """
        results = retriever.invoke(query)
        out = []
        for r in results:
            out.append(f"[{r.metadata.get('source','unknown')}]\n{r.page_content}")
        return "\n\n".join(out)[:6000]


    # -------------------------
    # BUILD THE CHATBOT AGENT
    # -------------------------
    llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0.2)

    chatbot_agent = Agent(
        role="Canada AI Strategy Chatbot",
        goal="Answer questions about Group 10's MIE1624 project.",
        backstory="Uses project documents (report + analyses).",
        tools=[project_rag_search],
        llm=llm,
        max_iter=1
    )

    def ask_chatbot(q: str):
        task = Task(
            description=f"User question:\n{q}\nUse project_rag_search for context.",
            agent=chatbot_agent,
            tools=[project_rag_search],
            expected_output="A grounded, concise answer."
        )
        crew = Crew(agents=[chatbot_agent], tasks=[task], process=Process.sequential)
        return crew.kickoff()

    return ask_chatbot


# Load the chatbot once
ask_chatbot = init_chatbot()

# ============================================================
# STREAMLIT UI
# ============================================================

if "msgs" not in st.session_state:
    st.session_state.msgs = []

# show past conversation
for m in st.session_state.msgs:
    with st.chat_message(m["role"]):
        st.markdown(m["text"])

# input field
user_q = st.chat_input("Ask about Canadaâ€™s AI strategyâ€¦")
if user_q:
    st.session_state.msgs.append({"role": "user", "text": user_q})
    with st.chat_message("user"):
        st.markdown(user_q)

    with st.chat_message("assistant"):
        with st.spinner("Thinking with our project documentsâ€¦"):
            answer = ask_chatbot(user_q)
            st.markdown(answer)

    st.session_state.msgs.append({"role": "assistant", "text": answer})